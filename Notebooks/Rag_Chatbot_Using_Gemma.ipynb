{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c4eac25",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2ad8d95-9d73-490e-a47b-67535d932c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Suppress Hugging Face and other warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c887a966-5b3e-4771-a861-7c745e62b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf921512-6c05-4fb0-aa6d-18af858ab16a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain.prompts import PromptTemplate\n",
    "import requests\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM,pipeline\n",
    "import torch\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "import joblib  # for saving the embedding model\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain_huggingface import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ca6399",
   "metadata": {},
   "source": [
    "## Loading and Describing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41e1a7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load data from Hugging Face Hub\n",
    "df_passages = pd.read_parquet(\n",
    "    \"hf://datasets/rag-datasets/rag-mini-bioasq/data/passages.parquet/part.0.parquet\"\n",
    ")\n",
    "df_test = pd.read_parquet(\n",
    "    \"hf://datasets/rag-datasets/rag-mini-bioasq/data/test.parquet/part.0.parquet\"\n",
    ")\n",
    "\n",
    "# 2. Reset index cleanly\n",
    "df_passages = df_passages.reset_index()\n",
    "df_test = df_test.reset_index()\n",
    "\n",
    "df_passages = df_passages.rename(columns={'id': 'id'})\n",
    "df_test = df_test.rename(columns={'id': 'id'})\n",
    "\n",
    "# 3. Create local save folder\n",
    "save_path = \"dataset/\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "# 4. Save locally as Parquet (fast & space-efficient)\n",
    "df_passages.to_parquet(save_path + \"passages.parquet\", index=False)\n",
    "df_test.to_parquet(save_path + \"test.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a928cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload locally to verify\n",
    "df_passages = pd.read_parquet(save_path + \"passages.parquet\")\n",
    "df_test = pd.read_parquet(save_path + \"test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "388f1bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passages shape: (40221, 2)\n",
      "Test shape: (4719, 4)\n",
      "\n",
      "Passages sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9797</td>\n",
       "      <td>New data on viruses isolated from patients wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11906</td>\n",
       "      <td>We describe an improved method for detecting d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                            passage\n",
       "0   9797  New data on viruses isolated from patients wit...\n",
       "1  11906  We describe an improved method for detecting d..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick checks\n",
    "print(\"Passages shape:\", df_passages.shape)\n",
    "print(\"Test shape:\", df_test.shape)\n",
    "\n",
    "print(\"\\nPassages sample:\")\n",
    "df_passages.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7870d262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>relevant_passage_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Is Hirschsprung disease a mendelian or a multi...</td>\n",
       "      <td>Coding sequence mutations in RET, GDNF, EDNRB,...</td>\n",
       "      <td>[20598273, 6650562, 15829955, 15617541, 230011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>List signaling molecules (ligands) that intera...</td>\n",
       "      <td>The 7 known EGFR ligands  are: epidermal growt...</td>\n",
       "      <td>[23821377, 24323361, 23382875, 22247333, 23787...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           question  \\\n",
       "0   0  Is Hirschsprung disease a mendelian or a multi...   \n",
       "1   1  List signaling molecules (ligands) that intera...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Coding sequence mutations in RET, GDNF, EDNRB,...   \n",
       "1  The 7 known EGFR ligands  are: epidermal growt...   \n",
       "\n",
       "                                relevant_passage_ids  \n",
       "0  [20598273, 6650562, 15829955, 15617541, 230011...  \n",
       "1  [23821377, 24323361, 23382875, 22247333, 23787...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nTest sample:\")\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e75a5be4-7e8a-455e-983a-fe48a8f43acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passages: (27975, 2)\n",
      "Test Q&A: (4719, 4)\n"
     ]
    }
   ],
   "source": [
    "# Clean: Remove rows where passage is null or duplicated\n",
    "df_passages = df_passages.dropna(subset=['passage'])\n",
    "df_passages = df_passages.drop_duplicates(subset='passage')\n",
    "\n",
    "# Clean test DataFrame\n",
    "df_test = df_test.dropna(subset=['question', 'answer'])\n",
    "df_test = df_test.drop_duplicates(subset='question')\n",
    "\n",
    "print(\"Passages:\", df_passages.shape)\n",
    "print(\"Test Q&A:\", df_test.shape)\n",
    "\n",
    "# Extract both chunks and doc_ids (removing nulls ensures alignment)\n",
    "chunks = df_passages['passage'].tolist()\n",
    "doc_ids = df_passages['id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df7671d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9797</td>\n",
       "      <td>New data on viruses isolated from patients wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11906</td>\n",
       "      <td>We describe an improved method for detecting d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16083</td>\n",
       "      <td>We have studied the effects of curare on respo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23188</td>\n",
       "      <td>Kinetic and electrophoretic properties of 230-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23469</td>\n",
       "      <td>Male Wistar specific-pathogen-free rats aged 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                            passage\n",
       "0   9797  New data on viruses isolated from patients wit...\n",
       "1  11906  We describe an improved method for detecting d...\n",
       "2  16083  We have studied the effects of curare on respo...\n",
       "3  23188  Kinetic and electrophoretic properties of 230-...\n",
       "4  23469  Male Wistar specific-pathogen-free rats aged 2..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_passages.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "909dd9f9-3916-4c46-b533-ab82d3ea0f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>relevant_passage_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Is Hirschsprung disease a mendelian or a multi...</td>\n",
       "      <td>Coding sequence mutations in RET, GDNF, EDNRB,...</td>\n",
       "      <td>[20598273, 6650562, 15829955, 15617541, 230011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>List signaling molecules (ligands) that intera...</td>\n",
       "      <td>The 7 known EGFR ligands  are: epidermal growt...</td>\n",
       "      <td>[23821377, 24323361, 23382875, 22247333, 23787...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Is the protein Papilin secreted?</td>\n",
       "      <td>Yes,  papilin is a secreted protein</td>\n",
       "      <td>[21784067, 19297413, 15094122, 7515725, 332004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Are long non coding RNAs spliced?</td>\n",
       "      <td>Long non coding RNAs appear to be spliced thro...</td>\n",
       "      <td>[22955974, 21622663, 22707570, 22955988, 24285...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Is RANKL secreted from the cells?</td>\n",
       "      <td>Receptor activator of nuclear factor κB ligand...</td>\n",
       "      <td>[22867712, 23827649, 21618594, 23835909, 24265...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Does metformin interfere thyroxine absorption?</td>\n",
       "      <td>No. There are not reported data indicating tha...</td>\n",
       "      <td>[26191653]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Which miRNAs could be used as potential biomar...</td>\n",
       "      <td>miR-200a, miR-100, miR-141, miR-200b, miR-200c...</td>\n",
       "      <td>[23918241, 23621186, 22246341, 23978303, 23888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Which acetylcholinesterase inhibitors are used...</td>\n",
       "      <td>Pyridostigmine and neostygmine are acetylcholi...</td>\n",
       "      <td>[21328290, 21133188, 15610702, 20663605, 21815...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Has Denosumab (Prolia) been approved by FDA?</td>\n",
       "      <td>Yes, Denosumab was approved by the FDA in 2010.</td>\n",
       "      <td>[24114694, 22540167, 21129866, 21170699, 23956...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>List the human genes encoding for the dishevel...</td>\n",
       "      <td>DVL-1\n",
       "DVL-2\n",
       "DVL-3</td>\n",
       "      <td>[16457155, 12883684, 19618470, 23836490, 88173...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           question  \\\n",
       "0   0  Is Hirschsprung disease a mendelian or a multi...   \n",
       "1   1  List signaling molecules (ligands) that intera...   \n",
       "2   2                   Is the protein Papilin secreted?   \n",
       "3   3                  Are long non coding RNAs spliced?   \n",
       "4   4                  Is RANKL secreted from the cells?   \n",
       "5   5     Does metformin interfere thyroxine absorption?   \n",
       "6   6  Which miRNAs could be used as potential biomar...   \n",
       "7   7  Which acetylcholinesterase inhibitors are used...   \n",
       "8   8       Has Denosumab (Prolia) been approved by FDA?   \n",
       "9   9  List the human genes encoding for the dishevel...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Coding sequence mutations in RET, GDNF, EDNRB,...   \n",
       "1  The 7 known EGFR ligands  are: epidermal growt...   \n",
       "2                Yes,  papilin is a secreted protein   \n",
       "3  Long non coding RNAs appear to be spliced thro...   \n",
       "4  Receptor activator of nuclear factor κB ligand...   \n",
       "5  No. There are not reported data indicating tha...   \n",
       "6  miR-200a, miR-100, miR-141, miR-200b, miR-200c...   \n",
       "7  Pyridostigmine and neostygmine are acetylcholi...   \n",
       "8    Yes, Denosumab was approved by the FDA in 2010.   \n",
       "9                                  DVL-1\n",
       "DVL-2\n",
       "DVL-3   \n",
       "\n",
       "                                relevant_passage_ids  \n",
       "0  [20598273, 6650562, 15829955, 15617541, 230011...  \n",
       "1  [23821377, 24323361, 23382875, 22247333, 23787...  \n",
       "2  [21784067, 19297413, 15094122, 7515725, 332004...  \n",
       "3  [22955974, 21622663, 22707570, 22955988, 24285...  \n",
       "4  [22867712, 23827649, 21618594, 23835909, 24265...  \n",
       "5                                         [26191653]  \n",
       "6  [23918241, 23621186, 22246341, 23978303, 23888...  \n",
       "7  [21328290, 21133188, 15610702, 20663605, 21815...  \n",
       "8  [24114694, 22540167, 21129866, 21170699, 23956...  \n",
       "9  [16457155, 12883684, 19618470, 23836490, 88173...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba12d2dc-e02e-42b4-a1bd-45334ad65c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4719, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b9dfa8b-9bfd-4662-adf1-cd01207aae88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9797</td>\n",
       "      <td>New data on viruses isolated from patients wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11906</td>\n",
       "      <td>We describe an improved method for detecting d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16083</td>\n",
       "      <td>We have studied the effects of curare on respo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23188</td>\n",
       "      <td>Kinetic and electrophoretic properties of 230-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23469</td>\n",
       "      <td>Male Wistar specific-pathogen-free rats aged 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24032</td>\n",
       "      <td>Tyrosine hydroxylase (TH) and phenylethanolami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30666</td>\n",
       "      <td>Hemolytic anemia is a well-recognized complica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>58611</td>\n",
       "      <td>(1) The RNA replicase induced by bacteriophage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>61441</td>\n",
       "      <td>Mice were inoculated with human sarcoid tissue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>83311</td>\n",
       "      <td>Bleomycin is potentially capable of inducing a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                            passage\n",
       "0   9797  New data on viruses isolated from patients wit...\n",
       "1  11906  We describe an improved method for detecting d...\n",
       "2  16083  We have studied the effects of curare on respo...\n",
       "3  23188  Kinetic and electrophoretic properties of 230-...\n",
       "4  23469  Male Wistar specific-pathogen-free rats aged 2...\n",
       "5  24032  Tyrosine hydroxylase (TH) and phenylethanolami...\n",
       "6  30666  Hemolytic anemia is a well-recognized complica...\n",
       "7  58611  (1) The RNA replicase induced by bacteriophage...\n",
       "8  61441  Mice were inoculated with human sarcoid tissue...\n",
       "9  83311  Bleomycin is potentially capable of inducing a..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_passages.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd83ec92",
   "metadata": {},
   "source": [
    "## Building Faiss Index and saving locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05fba1d3-38e7-42c4-99b0-04ecdc4a950f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building LangChain documents with metadata...\n",
      "Building FAISS index...\n",
      "FAISS index created.\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Build documents\n",
    "# =========================\n",
    "print(\"Building LangChain documents with metadata...\")\n",
    "docs = [\n",
    "    Document(page_content=text, metadata={\"doc_id\": doc_id})\n",
    "    for text, doc_id in zip(chunks, doc_ids)\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# Create FAISS index\n",
    "# =========================\n",
    "print(\"Building FAISS index...\")\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vector_db = FAISS.from_documents(docs, embedding_model)\n",
    "print(\"FAISS index created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "073df0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index saved to 'faiss_index_folder'.\n",
      "Embedding model saved to 'embedder_model_folder/'.\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Save FAISS index and embedder\n",
    "# =========================\n",
    "save_path = \"faiss_index_folder\"\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "# Save FAISS index\n",
    "vector_db.save_local(save_path)\n",
    "print(f\"FAISS index saved to '{save_path}'.\")\n",
    "\n",
    "# Save embedding model\n",
    "save_path = \"embedder_model_folder/\"\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "joblib.dump(embedding_model, os.path.join(save_path, \"model.pkl\"))\n",
    "print(f\"Embedding model saved to '{save_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "250f496e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model from disk...\n",
      "Embedding model loaded successfully.\n",
      "Loading FAISS index from disk...\n",
      "FAISS index loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# =========================\n",
    "# Load embedder\n",
    "# =========================\n",
    "save_path = \"faiss_index_folder\"\n",
    "embedder_path = \"embedder_model_folder/\"\n",
    "\n",
    "print(\"Loading embedding model from disk...\")\n",
    "embedding_model = joblib.load(os.path.join(embedder_path, \"embedding_model.pkl\"))\n",
    "print(\"Embedding model loaded successfully.\")\n",
    "\n",
    "# =========================\n",
    "# Load FAISS index\n",
    "# =========================\n",
    "print(\"Loading FAISS index from disk...\")\n",
    "vector_db_loaded = FAISS.load_local(save_path, embedding_model, allow_dangerous_deserialization=True)\n",
    "print(\"FAISS index loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bb93c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result 1:\n",
      "Doc ID: 17322504\n",
      "Content: Most cases of sudden cardiac death in young athletes (<35 years) are caused by \n",
      "inherited cardiomyop...\n",
      "\n",
      "Result 2:\n",
      "Doc ID: 1450882\n",
      "Content: Sudden death in athletes is a rare but tragic occurrence. Congenital \n",
      "cardiovascular abnormalities, ...\n",
      "\n",
      "Result 3:\n",
      "Doc ID: 9858396\n",
      "Content: The athlete projects the ultimate image of well-being in the health status \n",
      "spectrum. Nevertheless, ...\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Test retrieval\n",
    "# =========================\n",
    "query = \"What causes heart attack?\"\n",
    "results = vector_db_loaded.similarity_search(query, k=3)\n",
    "for i, doc in enumerate(results, start=1):\n",
    "    print(f\"\\nResult {i}:\")\n",
    "    print(f\"Doc ID: {doc.metadata['doc_id']}\")\n",
    "    print(f\"Content: {doc.page_content[:100]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e19906",
   "metadata": {},
   "source": [
    "## Downloading 'gemma-2b-it model' and saving in local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "652ec334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "018f7db7306e43f89ad0c2292229e5a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved google/gemma-2b-it to saved_models/gemma\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google/gemma-2b-it\"  # or \"google/gemma-7b-it\"\n",
    "save_dir = \"saved_models/gemma\"\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Download and save tokenizer & model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=\"auto\").to(\"mps\")\n",
    "model.save_pretrained(save_dir)\n",
    "\n",
    "print(f\"✅ Saved {model_name} to {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9478be61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183880879a864905873fdfa2d2dc7f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gemma loaded locally and ready\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model_dir = \"saved_models/gemma\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    trust_remote_code=True\n",
    ").to(device).eval()\n",
    "\n",
    "print(\"✅ Gemma loaded locally and ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce27c0bc",
   "metadata": {},
   "source": [
    "## Creating Gemma model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "345dcf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# Create HF text-generation pipeline =====\n",
    "gen_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=128,\n",
    "    num_beams=4,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    device=0 if device.type == \"cuda\" else -1\n",
    ")\n",
    "\n",
    "# Wrap in LangChain's HuggingFacePipeline =====\n",
    "llm_rewriter = HuggingFacePipeline(pipeline=gen_pipeline)\n",
    "\n",
    "# Prompt Template =====\n",
    "rewrite_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Provide several specific rewritten versions of the biomedical question, ranging from broad to precise. \n",
    "Output as 'Option 1', 'Option 2', etc.\n",
    "\n",
    "Question: {question}\n",
    "Rewritten:\"\"\"\n",
    ")\n",
    "\n",
    "# Chain =====\n",
    "rewrite_chain = rewrite_prompt | llm_rewriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd23fb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provide several specific rewritten versions of the biomedical question, ranging from broad to precise. \n",
      "Output as 'Option 1', 'Option 2', etc.\n",
      "\n",
      "Question: What are the causes of heart attack?\n",
      "Rewritten:\n",
      "1. What are the risk factors for heart attack?\n",
      "2. What are the contributing factors to the development of heart disease?\n",
      "3. What are the underlying causes of cardiovascular events?\n",
      "4. What are the factors that increase the risk of heart attack?\n",
      "5. What are the determinants of heart attack risk?\n"
     ]
    }
   ],
   "source": [
    "# 6. Test =====\n",
    "question = \"What are the causes of heart attack?\"\n",
    "result = rewrite_chain.invoke({\"question\": question})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b8ca40",
   "metadata": {},
   "source": [
    "## Main RAG code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63ea1bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_top_k(query, k=5):\n",
    "    results = vector_db.similarity_search(query, k=k)\n",
    "    return [(doc.page_content, doc.metadata.get(\"doc_id\")) for doc in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f315927f-a480-4a6d-b49d-65ab1ea39921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_query(question, preferred_option=\"Option 2\"):\n",
    "    output = rewrite_chain.invoke({\"question\": question})\n",
    "    \n",
    "    # Ensure we get the actual string from LangChain's output\n",
    "    if hasattr(output, \"content\"):  \n",
    "        output_text = output.content or \"\"\n",
    "    else:  \n",
    "        output_text = str(output)\n",
    "\n",
    "    for line in output_text.split(\"\\n\"):\n",
    "        if line.strip().startswith(preferred_option):\n",
    "            return line.split(\":\", 1)[1].strip()\n",
    "\n",
    "    # Fallback: return first option or original question\n",
    "    for line in output_text.split(\"\\n\"):\n",
    "        if line.strip().startswith(\"Option 1\"):\n",
    "            return line.split(\":\", 1)[1].strip()\n",
    "\n",
    "    return question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbb5fdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTENT_PATTERNS = {\n",
    "    \"symptoms\":  re.compile(r\"\\b(symptom|sign|clinical presentation|manifestation)\\b\", re.I),\n",
    "    \"causes\":    re.compile(r\"\\b(cause|etiolog|due to|result[s]? from|lead[s]? to|because)\\b\", re.I),\n",
    "    \"treatments\":re.compile(r\"\\b(treat|therapy|management|intervention|drug|medication)\\b\", re.I),\n",
    "    \"risks\":     re.compile(r\"\\b(risk factor|risk|predispos|associated with|correlate)\\b\", re.I),\n",
    "    \"mechanisms\":re.compile(r\"\\b(pathophysiolog|mechanism|how.*work|underlying process)\\b\", re.I),\n",
    "    \"definition\":re.compile(r\"\\b(what is|define|definition)\\b\", re.I),\n",
    "}\n",
    "\n",
    "def detect_question_intent(question: str) -> str:\n",
    "    q = question.lower()\n",
    "    # Priority: explicit patterns\n",
    "    for intent, pat in INTENT_PATTERNS.items():\n",
    "        if pat.search(q):\n",
    "            return intent\n",
    "    # Heuristics\n",
    "    if any(w in q for w in [\"cause\", \"etiology\", \"why\"]):\n",
    "        return \"causes\"\n",
    "    if any(w in q for w in [\"symptom\", \"sign\", \"presentation\"]):\n",
    "        return \"symptoms\"\n",
    "    if any(w in q for w in [\"treat\", \"therapy\", \"manage\", \"medicat\"]):\n",
    "        return \"treatments\"\n",
    "    if any(w in q for w in [\"risk\", \"predispos\"]):\n",
    "        return \"risks\"\n",
    "    if any(w in q for w in [\"mechanism\", \"how does it work\", \"pathophys\"]):\n",
    "        return \"mechanisms\"\n",
    "    if q.startswith(\"what is\") or q.startswith(\"define\"):\n",
    "        return \"definition\"\n",
    "    return \"general\"\n",
    "\n",
    "_SENT_SPLIT = re.compile(r\"(?<=[\\.\\?\\!])\\s+\")\n",
    "\n",
    "def split_sentences(text: str):\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return [s.strip() for s in _SENT_SPLIT.split(text) if s.strip()]\n",
    "\n",
    "# ----------- 2) Intent-specific context filtering (precision boost) ----------\n",
    "\n",
    "INTENT_CUE_SETS = {\n",
    "    \"causes\": [\n",
    "        r\"\\b(cause|caused by|etiolog\\w*|due to|because|results? from|triggered by|lead[s]? to)\\b\"\n",
    "    ],\n",
    "    \"symptoms\": [\n",
    "        r\"\\b(symptom|signs?|presents? with|manifestation)\\b\",\n",
    "        r\"\\b(headache|fever|cough|dyspnea|fatigue|myalgia|rash|nausea|diarrhea|vomit|pain|loss of smell|loss of taste)\\b\"\n",
    "    ],\n",
    "    \"treatments\": [\n",
    "        r\"\\b(treat|therapy|therapies|management|intervention|drug|medication|dose|dosing)\\b\"\n",
    "    ],\n",
    "    \"risks\": [\n",
    "        r\"\\b(risk factor|risk|predispos|associated with|correlat)\\b\"\n",
    "    ],\n",
    "    \"mechanisms\": [\n",
    "        r\"\\b(pathophysiolog\\w*|mechanism|biologic\\w* process|immune|inflammation|autoimmun\\w*)\\b\"\n",
    "    ],\n",
    "    \"definition\": [\n",
    "        r\"\\b(is defined as|refers to|is a|means)\\b\"\n",
    "    ],\n",
    "    \"general\": []  # keep broad\n",
    "}\n",
    "\n",
    "def filter_context_for_intent(context: str, intent: str, max_sents: int = 15) -> str:\n",
    "    sents = split_sentences(context)\n",
    "    if not sents:\n",
    "        return \"\"\n",
    "    cues = INTENT_CUE_SETS.get(intent, [])\n",
    "    if not cues:  # general → keep most informative (length heuristic)\n",
    "        ranked = sorted(sents, key=len, reverse=True)[:max_sents]\n",
    "        return \" \".join(ranked)\n",
    "\n",
    "    # Rank sentences by number of cue matches (then by length as tiebreaker)\n",
    "    compiled = [re.compile(pat, re.I) for pat in cues]\n",
    "    scored = []\n",
    "    for s in sents:\n",
    "        score = sum(1 for pat in compiled if pat.search(s))\n",
    "        if score > 0:\n",
    "            scored.append((score, len(s), s))\n",
    "    if not scored:\n",
    "        # fallback: return top long sentences rather than empty\n",
    "        ranked = sorted(sents, key=len, reverse=True)[:min(max_sents, 8)]\n",
    "        return \" \".join(ranked)\n",
    "\n",
    "    ranked = sorted(scored, key=lambda x: (-x[0], -x[1]))[:max_sents]\n",
    "    return \" \".join(s for _, __, s in ranked)\n",
    "\n",
    "# ------------------- 3) Intent-aware instruction templates -------------------\n",
    "\n",
    "INTENT_TEMPLATES = {\n",
    "    \"causes\": \"\"\"You are a biomedical expert.\n",
    "Using ONLY the context, answer the question by listing the CAUSES/ETIOLOGY explicitly mentioned.\n",
    "Rules:\n",
    "- Extract only statements that indicate causation (e.g., \"caused by\", \"due to\", \"results from\").\n",
    "- If causes are not directly stated, say exactly: \"I'm sorry, I cannot answer that question based on the provided information.\"\n",
    "- Be concise and structured (bullets).\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\",\n",
    "    \"symptoms\": \"\"\"You are a biomedical expert.\n",
    "Using ONLY the context, list ALL symptoms/signs mentioned, grouped logically (respiratory, neurological, cardiovascular, GI, mental health, etc.). Do not add anything not stated.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\",\n",
    "    \"treatments\": \"\"\"You are a biomedical expert.\n",
    "Using ONLY the context, summarize evidence-based treatments/management mentioned (drugs, interventions, dose notes if present). If none, use the exact fallback line.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\",\n",
    "    \"risks\": \"\"\"You are a biomedical expert.\n",
    "Using ONLY the context, list risk factors and associations mentioned. If none are present, use the exact fallback line.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\",\n",
    "    \"mechanisms\": \"\"\"You are a biomedical expert.\n",
    "Using ONLY the context, explain the pathophysiology/mechanisms mentioned. If mechanisms are not described, use the exact fallback line.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\",\n",
    "    \"definition\": \"\"\"You are a biomedical expert.\n",
    "Using ONLY the context, provide a crisp definition/description. If no definitional text is present, use the exact fallback line.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\",\n",
    "    \"general\": \"\"\"You are a biomedical expert.\n",
    "Using ONLY the context, answer as clearly and completely as possible.\n",
    "- Combine relevant points concisely.\n",
    "- Do not invent information not in the context.\n",
    "- If nothing in the context supports an answer, use the exact fallback line.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "FALLBACK_LINE = \"I'm sorry, I cannot answer that question based on the provided information.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcf06044",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def answer_with_gemma(question, context, tokenizer=None, model=None, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Biomedical QA with:\n",
    "    - intent detection\n",
    "    - intent-targeted context filtering\n",
    "    - structured, intent-specific prompting\n",
    "    - deterministic decoding with safety knobs\n",
    "    \"\"\"\n",
    "    intent = detect_question_intent(question)\n",
    "    focused_context = filter_context_for_intent(context, intent)\n",
    "\n",
    "    # If the context is empty after filtering, immediately fallback\n",
    "    if not focused_context.strip():\n",
    "        return FALLBACK_LINE\n",
    "\n",
    "    prompt = INTENT_TEMPLATES[intent].format(context=focused_context, question=question)\n",
    "\n",
    "    inputs = tokenizer([prompt], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=320,\n",
    "            num_beams=4,              # thorough but not too slow\n",
    "            do_sample=False,          # deterministic (prevents invalid 'temperature' issue)\n",
    "            no_repeat_ngram_size=3,\n",
    "            repetition_penalty=1.05,  # light touch\n",
    "            length_penalty=0.9,       # keep it concise\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    raw = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Remove echoed prompt if present\n",
    "    answer = raw.replace(prompt, \"\").strip()\n",
    "\n",
    "    # Guardrails: if the model hedges without giving content, or returns empty\n",
    "    if not answer or answer.lower().startswith(\"the context does not\") or answer.count(\"cannot answer\") > 0:\n",
    "        # Try a shorter, stricter follow-up once using same generation (no extra call if you prefer)\n",
    "        # Here we just fall back cleanly:\n",
    "        return FALLBACK_LINE\n",
    "\n",
    "    # If user asked for causes but none of the causal cues appear in the answer, fail safe:\n",
    "    if intent == \"causes\" and not re.search(r\"\\b(caused by|due to|results? from|because)\\b\", answer, re.I):\n",
    "        # It might still be valid, but to be safe when context is weak:\n",
    "        # Prefer to return fallback rather than hallucinate.\n",
    "        # If you want to be less strict, comment this out.\n",
    "        # Do a soft check: if very short and generic, fallback.\n",
    "        if len(answer) < 30:\n",
    "            return FALLBACK_LINE\n",
    "\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a87515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline(question, k=3):\n",
    "    # Step 1 – Rewrite query\n",
    "    rewritten = rewrite_query(question)\n",
    "\n",
    "    # Step 2 – Retrieve top-k passages (strings)\n",
    "    retrieved_passages = retrieve_top_k(rewritten, k)  # list[(text, score)] or list[str]\n",
    "    # Normalize to strings\n",
    "    passages = [p[0] if isinstance(p, (list, tuple)) else p for p in retrieved_passages]\n",
    "\n",
    "    # Step 3 – Build raw context\n",
    "    context = \"\\n\".join(passages)\n",
    "\n",
    "    # Step 4 – Generate answer\n",
    "    answer = answer_with_gemma(question, context, tokenizer=tokenizer, model=model, device=device)\n",
    "\n",
    "    # Step 5 – Structured output\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"rewritten\": rewritten,\n",
    "        \"context\": context,\n",
    "        \"answer\": answer\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febaa18e-2528-4ffb-9039-984ea5ab4dfd",
   "metadata": {},
   "source": [
    "## Examples using Gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e5a4c00-8cb4-4e66-8975-6c60ac740074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Question: What are the symptoms of COVID-19?\n",
      "\n",
      "\n",
      "\n",
      "Rewritten: What are the symptoms of COVID-19?\n",
      "\n",
      "\n",
      "\n",
      "Retrieved Context:\n",
      " We aimed this systematic review to analyze and review the currently available \n",
      "published literature related to long COVID, understanding its pattern, and \n",
      "predicting the long-term effects on survivors. We thoroughly searched the \n",
      "databases for relevant articles till May 2021. The research articles that met \n",
      "our inclusion and exclusion criteria were assessed and reviewed by two \n",
      "independent researchers. After preliminary screening of the identified articles \n",
      "through title and abstract, 249 were selected. Consequently, 167 full-text \n",
      "articles were assessed and reviewed based on our inclusion criteria and thus 20 \n",
      "articles were regarded as eligible and analyzed in the present analysis. All the \n",
      "studies included adult population aged between 18 and above 60 years. The median \n",
      "length of hospital stay of the COVID-19 patients during the acute infection \n",
      "phase ranged from 8 days to 17 days. The most common prevalent long-term \n",
      "symptoms in COVID-19 patients included persistent fatigue and dyspnea in almost \n",
      "all of the studies. Other reported common symptoms included: shortness of \n",
      "breath, cough, joint pain, chest pain or tightness, headache, loss of \n",
      "smell/taste, sore throat, diarrhea, loss of memory, depression, anxiety. \n",
      "Associated cardiovascular events included arrhythmias, palpitations and \n",
      "hypotension, increased HR, venous thromboembolic diseases, myocarditis, and \n",
      "acute/decompensated heart failure as well. Among neurological manifestations \n",
      "headache, peripheral neuropathy symptoms, memory issues, concentration, and \n",
      "sleep disorders were most commonly observed with varying frequencies. Mental \n",
      "health issues affecting mental abilities, mood fluctuations namely anxiety and \n",
      "depression, and sleep disorders were commonly seen. Further, diarrhea, vomiting, \n",
      "digestive disorders, and Loss of appetite or weight loss are common \n",
      "gastrointestinal manifestations. Therefore, appropriate clinical evaluation is \n",
      "required in long COVID cases which in turn may help us to identify the risk \n",
      "factors, etiology, and to my help, we treat them early with appropriate \n",
      "management strategies.\n",
      "Long COVID or post-COVID-19 syndrome first gained widespread recognition among \n",
      "social support groups and later in scientific and medical communities. This \n",
      "illness is poorly understood as it affects COVID-19 survivors at all levels of \n",
      "disease severity, even younger adults, children, and those not hospitalized. \n",
      "While the precise definition of long COVID may be lacking, the most common \n",
      "symptoms reported in many studies are fatigue and dyspnoea that last for months \n",
      "after acute COVID-19. Other persistent symptoms may include cognitive and mental \n",
      "impairments, chest and joint pains, palpitations, myalgia, smell and taste \n",
      "dysfunctions, cough, headache, and gastrointestinal and cardiac issues. \n",
      "Presently, there is limited literature discussing the possible pathophysiology, \n",
      "risk factors, and treatments in long COVID, which the current review aims to \n",
      "address. In brief, long COVID may be driven by long-term tissue damage (e.g. \n",
      "lung, brain, and heart) and pathological inflammation (e.g. from viral \n",
      "persistence, immune dysregulation, and autoimmunity). The associated risk \n",
      "factors may include female sex, more than five early symptoms, early dyspnoea, \n",
      "prior psychiatric disorders, and specific biomarkers (e.g. D-dimer, CRP, and \n",
      "lymphocyte count), although more research is required to substantiate such risk \n",
      "factors. While preliminary evidence suggests that personalized rehabilitation \n",
      "training may help certain long COVID cases, therapeutic drugs repurposed from \n",
      "other similar conditions, such as myalgic encephalomyelitis or chronic fatigue \n",
      "syndrome, postural orthostatic tachycardia syndrome, and mast cell activation \n",
      "syndrome, also hold potential. In sum, this review hopes to provide the current \n",
      "understanding of what is known about long COVID.\n",
      "COVID-19 is an ongoing pandemic with many challenges that are now extending to \n",
      "its intriguing long-term sequel. 'Long-COVID-19' is a term given to the \n",
      "lingering or protracted illness that patients of COVID-19 continue to experience \n",
      "even in their post-recovery phase. It is also being called 'post-acute \n",
      "COVID-19', 'ongoing symptomatic COVID-19', 'chronic COVID-19', 'post COVID-19 \n",
      "syndrome', and 'long-haul COVID-19'. Fatigue, dyspnea, cough, headache, brain \n",
      "fog, anosmia, and dysgeusia are common symptoms seen in Long-COVID-19, but more \n",
      "varied and debilitating injuries involving pulmonary, cardiovascular, cutaneous, \n",
      "musculoskeletal and neuropsychiatric systems are also being reported. With the \n",
      "data on Long-COVID-19 still emerging, the present review aims to highlight its \n",
      "epidemiology, protean clinical manifestations, risk predictors, and management \n",
      "strategies. With the re-emergence of new waves of SARS-CoV-2 infection, \n",
      "Long-COVID-19 is expected to produce another public health crisis on the heels \n",
      "of current pandemic. Thus, it becomes imperative to emphasize this condition and \n",
      "disseminate its awareness to medical professionals, patients, the public, and \n",
      "policymakers alike to prepare and augment health care facilities for continued \n",
      "surveillance of these patients. Further research comprising cataloging of \n",
      "symptoms, longer-ranging observational studies, and clinical trials are \n",
      "necessary to evaluate long-term consequences of COVID-19, and it warrants \n",
      "setting-up of dedicated, post-COVID care, multi-disciplinary clinics, and \n",
      "rehabilitation centers.\n",
      "\n",
      "\n",
      "\n",
      "Answer:\n",
      " Sure, here's a list of symptoms mentioned in the context:\n",
      "\n",
      "**Respiratory**\n",
      "- Fatigue\n",
      "- Dyspnea\n",
      "- Cough\n",
      "- Headache\n",
      "- Brain fog\n",
      "\n",
      "**Neurological**\n",
      " - Headache\n",
      " - Peripheral neuropathy symptoms\n",
      " - Memory issues\n",
      " - Concentration\n",
      " - Sleep disorders\n",
      "\n",
      "**Cardiovascular**\n",
      "None mentioned\n",
      "\n",
      "**GI** \n",
      "- Diarrhea\n",
      "- Vomiting\n",
      "- Digestive disorders\n",
      "- Weight loss\n"
     ]
    }
   ],
   "source": [
    "result = rag_pipeline(\"What are the symptoms of COVID-19?\")\n",
    "print(\"Original Question:\", result[\"question\"])\n",
    "print(\"\\n\\n\")\n",
    "print(\"Rewritten:\", result[\"rewritten\"])\n",
    "print(\"\\n\\n\")\n",
    "print(\"Retrieved Context:\\n\", result[\"context\"])\n",
    "print(\"\\n\\n\")\n",
    "print(\"Answer:\\n\", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f75afe5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Question: What is the cause of fever?\n",
      "\n",
      "\n",
      "\n",
      "Rewritten: What is the cause of fever?\n",
      "\n",
      "\n",
      "\n",
      "Retrieved Context:\n",
      " Fever is the most common reason that children and infants are brought to \n",
      "emergency departments. Emergency physicians face the challenge of quickly \n",
      "distinguishing benign from life-threatening conditions. The management of fever \n",
      "in children is guided by the patient's age, immunization status, and immune \n",
      "status as well as the results of a careful physical examination and appropriate \n",
      "laboratory tests and radiographic views. In this article, the evaluation and \n",
      "treatment of children with fevers of known and unknown origin are described. \n",
      "Causes of common and dangerous conditions that include fever in their \n",
      "manifestation are also discussed.\n",
      "11,119 patients with scarlet fever admitted in the last sixteen years, from 1973 \n",
      "to 1988, to Sapporo City General Hospital, were studied statistically on \n",
      "symptoms and laboratory findings. The results were summarized as follows: 1. \n",
      "Annual number of patients have reduced suddenly since 1981, and become zero in \n",
      "1989. The patients increased in number during the winter season. Eighty two \n",
      "percent of the cases were between 3 and 8 years of age, and the average age was \n",
      "5.8 year-old. 2. Cases of above-38 degrees C temperature were seen in about \n",
      "81.4%, and from 2 to 5 days-duration of temperature were seen in 86.6% of the \n",
      "patients in the year 1976. Cases of above-moderate rash were observed in 68.2%, \n",
      "sever redness of throat in 29.9%, strawberry tongue in 86.3% and angular \n",
      "stomatitis in 37.7% of the patients. In recent statistical analysis (1982-1988), \n",
      "we found, however, a tendency that patients having stronger symptoms were being \n",
      "introduced to our hospital. 3. The higher rates of cases showing elevated ASD \n",
      "titer were seen in the elder patients and in the winter. C-reactive protein \n",
      "(CRP) titers were mostly in the range of (-) to (greater than or equal to 6+), \n",
      "having 2.4 + on an average. 4. Patients who developed into overt nephritis were \n",
      "not seen. Cases of microscopic hematuria (greater than or equal to 3 red cells/f \n",
      "in urine sediments), however, were observed in 1.1% (125/11,119). Sever \n",
      "complications were hardly seen. 5. Reappearance of beta-hemolytic streptococci \n",
      "(on a week after discharge) were found in 3.1% (241/7,877). 6. Reinfection or \n",
      "relapse cases of scarlet fever were found in 6.7% (642/9,585).(ABSTRACT \n",
      "TRUNCATED AT 250 WORDS)\n",
      "Subacute (de Quervain's) thyroiditis is a rare but important cause of fever of \n",
      "unknown origin. Most cases of subacute thyroiditis are caused by a variety of \n",
      "viruses, for example, Coxsackie, cytomegalovirus, Epstein-Barr virus, and \n",
      "adenovirus. Influenza immunization or infection may cause subacute thyroiditis. \n",
      "We present the first reported case of a fever of unknown origin due to seasonal \n",
      "influenza A in a 67-year-old woman.\n",
      "\n",
      "\n",
      "\n",
      "Answer:\n",
      " Influenza A virus may cause fever.\n",
      "\n",
      "Explanation:\n",
      "The passage does not specify the exact cause of the fever, only stating that it may be caused by influenza A virus.\n"
     ]
    }
   ],
   "source": [
    "result = rag_pipeline(\"What is the cause of fever?\")\n",
    "print(\"Original Question:\", result[\"question\"])\n",
    "print(\"\\n\\n\")\n",
    "print(\"Rewritten:\", result[\"rewritten\"])\n",
    "print(\"\\n\\n\")\n",
    "print(\"Retrieved Context:\\n\", result[\"context\"])\n",
    "print(\"\\n\\n\")\n",
    "print(\"Answer:\\n\", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a98e5adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Question: Who is the president of US?\n",
      "\n",
      "\n",
      "\n",
      "Rewritten: Who is the president of US?\n",
      "\n",
      "\n",
      "\n",
      "Retrieved Context:\n",
      " There are 219 virus species that are known to be able to infect humans. The \n",
      "first of these to be discovered was yellow fever virus in 1901, and three to \n",
      "four new species are still being found every year. Extrapolation of the \n",
      "discovery curve suggests that there is still a substantial pool of undiscovered \n",
      "human virus species, although an apparent slow-down in the rate of discovery of \n",
      "species from different families may indicate bounds to the potential range of \n",
      "diversity. More than two-thirds of human viruses can also infect non-human \n",
      "hosts, mainly mammals, and sometimes birds. Many specialist human viruses also \n",
      "have mammalian or avian origins. Indeed, a substantial proportion of mammalian \n",
      "viruses may be capable of crossing the species barrier into humans, although \n",
      "only around half of these are capable of being transmitted by humans and around \n",
      "half again of transmitting well enough to cause major outbreaks. A few possible \n",
      "predictors of species jumps can be identified, including the use of \n",
      "phylogenetically conserved cell receptors. It seems almost inevitable that new \n",
      "human viruses will continue to emerge, mainly from other mammals and birds, for \n",
      "the foreseeable future. For this reason, an effective global surveillance system \n",
      "for novel viruses is needed.\n",
      "Via building computational (typically mathematical and computer simulation) \n",
      "models, human performance modeling (HPM) quantifies, predicts, and maximizes \n",
      "human performance, human-machine system productivity and safety. This paper \n",
      "describes and summarizes the five key questions of human performance modeling: \n",
      "1) Why we build models of human performance; 2) What the expectations of a good \n",
      "human performance model are; 3) What the procedures and requirements in building \n",
      "and verifying a human performance model are; 4) How we integrate a human \n",
      "performance model with system design; and 5) What the possible future directions \n",
      "of human performance modeling research are. Recent and classic HPM findings are \n",
      "addressed in the five questions to provide new thinking in HPM's motivations, \n",
      "expectations, procedures, system integration and future directions.\n",
      "nan\n",
      "\n",
      "\n",
      "\n",
      "Answer:\n",
      " I'm sorry, I cannot answer that question based on the provided information.\n"
     ]
    }
   ],
   "source": [
    "result = rag_pipeline(\"Who is the president of US?\")\n",
    "print(\"Original Question:\", result[\"question\"])\n",
    "print(\"\\n\\n\")\n",
    "print(\"Rewritten:\", result[\"rewritten\"])\n",
    "print(\"\\n\\n\")\n",
    "print(\"Retrieved Context:\\n\", result[\"context\"])\n",
    "print(\"\\n\\n\")\n",
    "print(\"Answer:\\n\", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff1ca37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
